{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction of practice 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:106.0) Gecko/20100101 Firefox/106.0'}\n",
    "resp = requests.get('https://news.google.com/search?q=apple', headers = headers)\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in soup.find_all('a', class_ = \"DY5T1d RZIKme\"):\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for i in soup.find_all('a', class_ = \"DY5T1d RZIKme\"):\n",
    "    links.append(\"https://news.google.com\" + i['href'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "for i in soup.find_all('time', class_ = \"WW6dff uQIVzc Sksgp slhocf\"):\n",
    "    t = i['datetime']\n",
    "    t = datetime.datetime.strptime(t, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(links[0])\n",
    "r = requests.get(links[0], headers =headers)\n",
    "s = BeautifulSoup(r.content)\n",
    "print(s.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s.find('a', jsname = \"tljFtd\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 7 : Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Read csv file into a pandas dataframe\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\csv_to_clean.csv\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Find the standard missing values isnull function\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non standard missing values : na_values in the read_csv function\n",
    "#use of unique function to identify them\n",
    "missing_values= ['na', '--']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\csv_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "print(df)\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Unexpected format missing values : check if value can be int for example\n",
    "for index, lines in df.iterrows():\n",
    "    try:\n",
    "        a = int(lines['OWN_OCCUPIED'])\n",
    "        print(a)\n",
    "        df.iloc[3, 3] = numpy.nan\n",
    "    except:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a bit about try/except\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        continue\n",
    "except:\n",
    "    print('error')\n",
    "print('my code continue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Check the sum of missing values\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YOUR TURN (15 minutes) => Then break\n",
    "#Find all missing values in the provided dataframe\n",
    "#Check all the null\n",
    "#Find the other types of missing values\n",
    "#There are '-', 'ERROR', wrong date, 'NaN', no data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "missing_values= ['-', 'ERROR']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\Apple_price_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "print(df.isnull().sum())\n",
    "\n",
    "for index, lines in df.iterrows():\n",
    "    try:\n",
    "        a = int(lines['Date'])\n",
    "        print(a)\n",
    "        df.loc[index, 'Date'] = np.nan\n",
    "    except:\n",
    "        pass\n",
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replacing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload df\n",
    "missing_values= ['na', '--']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\csv_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete lines with dropna with subset and inplace arguments\n",
    "# df = df.dropna()\n",
    "# print(df)\n",
    "df.dropna(inplace = True, subset = 'ST_NUM')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location based replacement with the loc function\n",
    "df.loc[3, 'NUM_BATH'] = 1\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values with a number (fillna() function with inplace arg)\n",
    "df.fillna(0, inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the missing values with a median \n",
    "#(calculate median and then use the replace with a number)\n",
    "# print(df)\n",
    "print(df['NUM_BEDROOMS'].mean())\n",
    "df['NUM_BEDROOMS'].fillna(df['NUM_BEDROOMS'].mean(), inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing the values by the one before or after : df.fillna(method='bfill')\n",
    "df['NUM_BEDROOMS'].fillna(method = 'bfill', inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN 5 minutes => 12:27\n",
    "#replace all the missing values in the previous dataframe with the frontfilling (ffill) method \n",
    "#put 0 for the first ones\n",
    "df.fillna(method = 'ffill', inplace = True)\n",
    "df.fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing useless data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload df\n",
    "import pandas as pd\n",
    "missing_values= ['na', '--']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\csv_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the drop() function with inplace and axis arg\n",
    "df.drop(['PID'], axis = 1, inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the drop duplicates to remove useless lines\n",
    "df.drop_duplicates(inplace = True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN 5 minutes\n",
    "#Drop all duplicates in your df\n",
    "#get number of rows\n",
    "#drop duplicates\n",
    "#get number of row again\n",
    "missing_values= ['-', 'ERROR']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\Apple_price_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "print(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload df\n",
    "import pandas as pd\n",
    "missing_values= ['na', '--']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\csv_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#With the describe method\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# With the plot method\n",
    "df.plot(y = 'SQ_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the df in the range\n",
    "df = df[df['SQ_M'] < 10000]\n",
    "df.plot(y = 'SQ_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN 10 minutes\n",
    "#Find the outliers in your dataset and remove them\n",
    "import pandas as pd\n",
    "missing_values= ['-', 'ERROR']\n",
    "df = pd.read_csv(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_7\\Apple_price_to_clean.csv\",\n",
    "                na_values = missing_values)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df = df[df['High'] > 0]\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(x = 'Date', y = 'Low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Low'] < 200]\n",
    "df.plot(x = 'Date', y = 'Low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Open'] < 200]\n",
    "df.plot(x = 'Date', y = 'Open')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
