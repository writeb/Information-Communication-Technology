{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction of practice 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.linear_model as skmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6]\n",
      " [10]\n",
      " [ 2]\n",
      " [ 3]\n",
      " [ 4]\n",
      " [ 0]\n",
      " [ 7]\n",
      " [ 8]\n",
      " [ 9]\n",
      " [ 1]]\n",
      "[[130]\n",
      " [ 21]\n",
      " [ 43]\n",
      " [ 76]\n",
      " [105]\n",
      " [  3]\n",
      " [167]\n",
      " [162]\n",
      " [ 91]\n",
      " [ 15]]\n",
      "[[ 36]\n",
      " [100]\n",
      " [  4]\n",
      " [  9]\n",
      " [ 16]\n",
      " [  0]\n",
      " [ 49]\n",
      " [ 64]\n",
      " [ 81]\n",
      " [  1]]\n",
      "[[ 216]\n",
      " [1000]\n",
      " [   8]\n",
      " [  27]\n",
      " [  64]\n",
      " [   0]\n",
      " [ 343]\n",
      " [ 512]\n",
      " [ 729]\n",
      " [   1]]\n"
     ]
    }
   ],
   "source": [
    "x1 = [6, 10, 2, 3, 4, 0, 7, 8, 9, 1]\n",
    "y = [130, 21, 43, 76, 105, 3, 167, 162, 91, 15]\n",
    "arr_x1 = np.array(x1).reshape(-1,1)\n",
    "print(arr_x1)\n",
    "arr_y = np.array(y).reshape(-1,1)\n",
    "print(arr_y)\n",
    "arr_x2 = arr_x1**2\n",
    "arr_x3 = arr_x1**3\n",
    "print(arr_x2)\n",
    "print(arr_x3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eq: 8.71*x + 37.75\n",
      "score is : 0.26\n"
     ]
    }
   ],
   "source": [
    "model = skmod.LinearRegression()\n",
    "model = model.fit(arr_x1, arr_y)\n",
    "print(\"Eq: {:.2f}*x + {:.2f}\".format(model.coef_[0][0], model.intercept_[0]) )\n",
    "print(\"score is : {:.2f}\".format(model.score(arr_x1, arr_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree2\n",
    "arr_x12 = np.hstack([arr_x1, arr_x2])\n",
    "model2 = skmod.LinearRegression().fit(arr_x12, arr_y)\n",
    "print(\"Eq: {:.2f}*x + {:.2f}*x**2 + {:.2f}\".format(model2.coef_[0][0],\n",
    "                                                   model2.coef_[0][1], \n",
    "                                                   model2.intercept_[0]))\n",
    "print(\"score is : {:.2f}\".format(model2.score(arr_x12, arr_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#degree3\n",
    "arr_x123 = np.hstack([arr_x1, arr_x2, arr_x3])\n",
    "model3 = skmod.LinearRegression().fit(arr_x123, arr_y)\n",
    "print(\"Eq: {:.2f}*x + {:.2f}*x**2 +{:.2f}*x**3 + {:.2f}\".format(\n",
    "                                                    model3.coef_[0][0],\n",
    "                                                   model3.coef_[0][1],\n",
    "                                                   model3.coef_[0][2],\n",
    "                                                   model3.intercept_[0]))\n",
    "print(\"score is : {:.2f}\".format(model3.score(arr_x123, arr_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(arr_x1, arr_y)\n",
    "plt.plot([0,10], model.predict(np.array([[0], [10]])))\n",
    "x_for_plot = np.arange(0,10,0.1).reshape(-1,1) #like range\n",
    "x2_for_plot = x_for_plot**2\n",
    "plt.plot(x_for_plot, model2.predict(np.hstack([x_for_plot, x2_for_plot])))\n",
    "x3_for_plot = x_for_plot**3\n",
    "plt.plot(x_for_plot, model3.predict(np.hstack([x_for_plot, x2_for_plot, x3_for_plot])))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11: Machine Learning III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some package\n",
    "import numpy as np\n",
    "import sklearn.linear_model as skmod\n",
    "import sklearn.preprocessing as skprepro\n",
    "import sklearn.model_selection as sksel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The polynomial features object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create data and reshape it\n",
    "x1 = [6, 10, 2, 3, 4, 0, 7, 8, 9, 1]\n",
    "arr_x1 = np.array(x1).reshape(-1,1)\n",
    "print(arr_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the polynomial feature object from the preprocessing module\n",
    "#PolynomialFeatures() function\n",
    "#choose the degree and don't include bias\n",
    "poly2 = skprepro.PolynomialFeatures(degree = 2, include_bias = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Transform your data into fetaures of degree two, fit_transform() function\n",
    "arr_x_poly = poly2.fit_transform(arr_x)\n",
    "print(arr_x_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your turn (10 minutes)\n",
    "#From the data of practice, make a polynomial regression of degree 8\n",
    "#print the coef of the model\n",
    "#degree2\n",
    "# arr_x12 = np.hstack([arr_x1, arr_x2]) #replace this line\n",
    "#create polynomial object\n",
    "poly8 = skprepro.PolynomialFeatures(8, include_bias = False)\n",
    "#model:\n",
    "model = skmod.LinearRegression().fit(poly8.fit_transform(arr_x1), arr_y)\n",
    "#print coef\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's create data, you can check this code at home\n",
    "data_x = np.random.normal(9, 4, 100)\n",
    "data_y = np.random.randint(70,130, size = (len(data_x)))/100*(data_x*data_x*8 + 2*data_x + 5)\n",
    "plt.scatter(data_x, data_y)\n",
    "data_x = data_x.reshape(-1,1)\n",
    "data_y = data_y.reshape(-1,1)\n",
    "# print(data_x)\n",
    "# print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's keep 20 % of our data aside\n",
    "data_x_train = data_x[:80]\n",
    "data_x_test = data_x[80:]\n",
    "data_y_train = data_y[:80]\n",
    "data_y_test = data_y[80:]\n",
    "plt.scatter(data_x_train, data_y_train)\n",
    "plt.scatter(data_x_test, data_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#choose a test and train set with scikit-learn:\n",
    "#import sklearn.model_selection and use the train_test_split() function\n",
    "#The order is train/test, train/test\n",
    "import sklearn.model_selection as sksel\n",
    "data_x_train, data_x_test, data_y_train, data_y_test = \\\n",
    "                        sksel.train_test_split(data_x, \n",
    "                                               data_y, \n",
    "                                               train_size = 0.75, \n",
    "                                               shuffle = True)\n",
    "\n",
    "plt.scatter(data_x_train, data_y_train)\n",
    "plt.scatter(data_x_test, data_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Let's use the Polynomial transform of the sklearn.preprocessing module\n",
    "poly2 = skprepro.PolynomialFeatures(2, include_bias = False)\n",
    "data_x_train_poly2 = poly2.fit_transform(data_x_train)\n",
    "data_x_test_poly2 = poly2.fit_transform(data_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's make our regression of degree 2\n",
    "model2 = skmod.LinearRegression().fit(data_x_train_poly2, data_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot our result\n",
    "plt.scatter(data_x_train, data_y_train)\n",
    "plt.scatter(data_x_test, data_y_test)\n",
    "plt.plot(np.arange(0,18,0.1), model2.predict(poly2.fit_transform(np.arange(0,18,0.1).reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's do for all regression for degree 8\n",
    "poly8 = skprepro.PolynomialFeatures(8, include_bias = False)\n",
    "data_x_train_poly8 = poly8.fit_transform(data_x_train)\n",
    "data_x_test_poly8 = poly8.fit_transform(data_x_test)\n",
    "model8 = skmod.LinearRegression().fit(data_x_train_poly8, data_y_train)\n",
    "plt.scatter(data_x_train, data_y_train)\n",
    "plt.scatter(data_x_test, data_y_test)\n",
    "plt.plot(np.arange(0,18,0.1), model2.predict(poly2.fit_transform(np.arange(0,18,0.1).reshape(-1,1))))\n",
    "plt.plot(np.arange(0,18,0.1), model8.predict(poly8.fit_transform(np.arange(0,18,0.1).reshape(-1,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Result of our model of the training set: the score function \n",
    "#(1 = perfect fitting, 0 = no fitting at all)\n",
    "print(\"Training :\", model2.score(data_x_train_poly2, data_y_train))\n",
    "print(\"Testing :\", model2.score(data_x_test_poly2, data_y_test))\n",
    "print('-'*20)\n",
    "print(\"Training :\", model8.score(data_x_train_poly8, data_y_train))\n",
    "print(\"Testing :\", model8.score(data_x_test_poly8, data_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Result of several runs\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Values scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The logic behind scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create two features with different size with random (use function np.random.randint())\n",
    "data_x1 = np.random.randint(10000, 20000, size = (20))\n",
    "data_x2 = np.random.randint(0, 10, size = (20))\n",
    "print(data_x1)\n",
    "print(data_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try to plot it together\n",
    "plt.scatter(range(20), data_x1)\n",
    "plt.scatter(range(20), data_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can scale our data with normalization ((x - xmin)/(xmax - xmin))\n",
    "data_x1_norm = (data_x1 - min(data_x1))/(max(data_x1)- min(data_x1))\n",
    "data_x2_norm = (data_x2 - min(data_x2))/(max(data_x2)- min(data_x2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's plot it again\n",
    "\n",
    "plt.scatter(range(20), data_x1_norm)\n",
    "plt.scatter(range(20), data_x2_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can scale our data with standardization\n",
    "data_x1_stan = (data_x1 - np.mean(data_x1))/np.std(data_x1)\n",
    "data_x2_stan = (data_x2 - np.mean(data_x2))/np.std(data_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can now plot our data\n",
    "plt.scatter(range(20), data_x1_stan)\n",
    "plt.scatter(range(20), data_x2_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The difference between normalisation and standardization when there is outliers\n",
    "#Let's plot it\n",
    "data_x1[0] = -100_000\n",
    "data_x1_norm = (data_x1 - min(data_x1))/(max(data_x1)- min(data_x1))\n",
    "data_x2_norm = (data_x2 - min(data_x2))/(max(data_x2)- min(data_x2))\n",
    "plt.scatter(range(20), data_x1_norm)\n",
    "plt.scatter(range(20), data_x2_norm)\n",
    "plt.show()\n",
    "data_x1_stan = (data_x1 - np.mean(data_x1))/np.std(data_x1)\n",
    "data_x2_stan = (data_x2 - np.mean(data_x2))/np.std(data_x2)\n",
    "plt.scatter(range(20), data_x1_stan)\n",
    "plt.scatter(range(20), data_x2_stan)\n",
    "plt.ylim(-1.1,1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The scikit-learn object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the scaler object StandardScaler() object\n",
    "scaler = skprepro.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#prepare our data: 2 columns because 2 features\n",
    "data_x = np.hstack([data_x1.reshape(-1,1), data_x2.reshape(-1,1)])\n",
    "print(data_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#use it on your data with the fit(), transform(), fit_transform()\n",
    "scaler_f = scaler.fit(data_x)\n",
    "data_x_stan = scaler_f.transform(data_x)\n",
    "# print(data_x_stan)\n",
    "print(scaler_f.transform([[5, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use inverse_transform method to come back for standardized data to real data\n",
    "print(scaler.inverse_transform([[0.01, 0.01]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#YOUR TURN (10 minutes)\n",
    "#On the file in Teams (use copy past to transfer it in python), \n",
    "#tranform the three lists in a 10*3 matrix of standardized features\n",
    "l1 = np.array([22, 85, 96, 81, 68, 97, 29, 61, 73, 86])\n",
    "l2 = np.array([1489022, 1073767, 1975250, 1493073, 1063635, 1017921, 1206827, 1217274, 1933018, 1325618])\n",
    "l3 = np.array([-99.67, -99.37, -99.08, -99.54, -99.8, -99.21, -99.73, -99.78, -99.6, -99.48])\n",
    "l = np.hstack([l1.reshape(-1,1), l2.reshape(-1,1), l3.reshape(-1,1) ])\n",
    "scaler_f = skprepro.StandardScaler()\n",
    "# scaler_f = scaler.fit(l)\n",
    "# l_stan = scaler.transform(l)\n",
    "l_stan = scaler_f.fit_transform(l)\n",
    "print(l_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN (10 minutes)\n",
    "#Make a linear regression with the three features (l1, l2 and l3) and the label (l4)\n",
    "#with standardized and non-standardized features\n",
    "# what is the prediction of both model for fatures: [30, 1600000, -99.5]\n",
    "l4 = np.array([-182, -254.3,  -71  , -172, -261 , -262, -237, -231, -85, -204])\n",
    "l4 = l4.reshape(-1,1)\n",
    "scaler_l = skprepro.StandardScaler()\n",
    "l4_stan = scaler_l.fit_transform(l4)\n",
    "print(l4_stan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skmod.LinearRegression().fit(l_stan, l4_stan)\n",
    "x_predict =  [30, 1600000, -99.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_predict =  np.array([30, 1600000, -99.5]).reshape(-1,1)\n",
    "x_predict_stan = scaler_f.transform(np.array([[30, 1600000, -99.5]]))\n",
    "print(x_predict_stan)\n",
    "y_predict_stan = model.predict(x_predict_stan)\n",
    "print(scaler_l.inverse_transform(y_predict_stan))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
