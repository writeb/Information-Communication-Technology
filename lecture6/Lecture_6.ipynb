{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURE 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction of the practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://query1.finance.yahoo.com/v7/finance/download/MSFT?period1=1633828168&period2=1665364168&interval=1d&events=history&includeAdjustedClose=true', \n",
    "                    headers = headers)\n",
    "\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "df = pd.read_csv(io.StringIO(resp.content.decode('utf-8')))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://query1.finance.yahoo.com/v7/finance/download/MSFT?period1=1633828168&period2=1665364168&interval=1d&events=history&includeAdjustedClose=true')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = ['TSLA', 'MSFT', 'AAPL']\n",
    "for i in l:\n",
    "    headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "    resp = requests.get('https://query1.finance.yahoo.com/v7/finance/download/'+i+'?period1=1633828168&period2=1665364168&interval=1d&events=history&includeAdjustedClose=true', \n",
    "                        headers = headers)\n",
    "\n",
    "    import pandas as pd\n",
    "    import io\n",
    "    df = pd.read_csv(io.StringIO(resp.content.decode('utf-8')))\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reminder => make a request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN: Make a request to any website (except websites with login requiered) and print the html code\n",
    "#10 minutes => just print the content of the response => 17:30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#install and import request library\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a request\n",
    "resp = requests.get('https://www.google.com')\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use header with user-agent information for better result\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://www.google.com', headers = headers)\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup and Html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the html file of a website\n",
    "with open(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_6\\html_example.html\", 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install an import beautiful soup\n",
    "# for installation => pip install bs4\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the soup !\n",
    "# content is resp.content (where resp = requests.get(....))\n",
    "soup = BeautifulSoup(content)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN\n",
    "#Make a soup of athe weather website (link on teams)\n",
    "#10 minutes => 17:44\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://www.accuweather.com/en/kz/almaty/222191/weather-forecast/222191', headers = headers)\n",
    "soup = BeautifulSoup(resp.content)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting a html file in my files\n",
    "with open(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_6\\html_example.html\", 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "# print(content)\n",
    "soup = BeautifulSoup(content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prettify\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going trough tags\n",
    "print(soup.div.div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN print the following tag ...\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://www.accuweather.com/en/kz/almaty/222191/weather-forecast/222191', headers = headers)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "print(type(soup.body.div.div.div.div.div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration on children of a tag:\n",
    "with open(r\"D:\\KBTU\\2022-2023\\Python Course\\Course\\Lecture\\Lecture_6\\html_example.html\", 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "# print(content)\n",
    "soup = BeautifulSoup(content)\n",
    "\n",
    "# for child in soup.aside.ul.children:\n",
    "#     print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On all descendant\n",
    "for child in soup.header.descendants:\n",
    "    print(child)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN : print all descendats  of a tag: div class = \"template-root\"\n",
    "#5 minutes\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://www.accuweather.com/en/kz/almaty/222191/weather-forecast/222191', headers = headers)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "for desc in soup.body.div.descendants:\n",
    "    print(desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the content of a tag\n",
    "print(soup.body.div.header.contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the string of a tag (only if no more children)\n",
    "print(soup.body.div.header.h1.string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding all\n",
    "print(soup.div.header.div.find_all('a'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more about find_all\n",
    "# filtering with id\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://www.accuweather.com/en/kz/almaty/222191/weather-forecast/222191', headers = headers)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')\n",
    "\n",
    "print(soup.find_all('div', id = 'bottom'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering with class\n",
    "print(soup.find_all('div', class_ = 'page-subnav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering with several attribute\n",
    "attrs = {'class' : 'header-city-link'}\n",
    "print(soup.find_all('div', attrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.find_all('a', attrs)[0]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOUR TURN : Get the current temperature and today air quality in the weather website\n",
    "#10 minutes\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "headers = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:105.0) Gecko/20100101 Firefox/105.0'}\n",
    "resp = requests.get('https://www.accuweather.com/en/kz/almaty/222191/weather-forecast/222191', headers = headers)\n",
    "soup = BeautifulSoup(resp.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = ('')\n",
    "print(soup.find_all('a', class_ = 'cur-con-weather-card')[0].find_all('div', class_ = 'temp'))\n",
    "# print(soup.find_all('div', class_ = 'page-column-1')[0].find_all('div', class_ = 'temp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with KBTU website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Turn:\n",
    "#Get all image of KBTU website\n",
    "#Then get image of academic staff only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
